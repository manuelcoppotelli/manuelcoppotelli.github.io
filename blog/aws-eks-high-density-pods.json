{"slug":"aws-eks-high-density-pods","title":"AWS EKS high-density pods","date":"2021-11-23T00:00:00.000Z","excerpt":"AWS recently released a new version of the AWS-CNI that allows more Pods per node...","tags":["Cloud","AWS","Kubernetes","CNI"],"html":"<p>AWS recently released a new version of the AWS CNI that allows more Pods to be\ndeployed within each EC2 instance. Having an higher pod density results in more\nefficiency and a significative reduction in EC2 costs necessary to run the same\nnumber of pods. How does the solution work under the hood? And if it’s that\ngood, why has not been released before?</p>\n<h2>A bit of background</h2>\n<p>In order to understand the changes that the new version brings, it is necessary\na bit of background on how intra-node networking works in Kubernetes.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/intra-node-networking.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/intra-node-networking.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/intra-node-networking.png\" alt=\"Kubernetes Intra-node Networking\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>Each time a new pod is created, the kubelet agent delegates:</p>\n<ol><li>Creating the container to the <em>Container Runtime Interface</em></li>\n<li>Attaching the container to the network to the <em>Container Network Interface</em></li>\n<li>Mounting volumes to the <em>Container Storage Interface</em></li></ol>\n<p>But for the scope of this post, let’s focus on the CNI part.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/node-cni.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/node-cni.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/node-cni.png\" alt=\"Kubernetes Node CNI\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>Each pod has its own isolated Linux network namespace and is attached to a\nbridge. The CNI is in charge of creating the bridge, assigning the IP and\nconnecting <code>veth0</code> to the <code>docker0</code>.</p>\n<h2>AWS is doing it differently</h2>\n<p>This is how most of the CNIs works and what happens most of the time, but\ndifferent CNIs might use other ways to connect the container to the network.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/node-unordinary-cni.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/node-unordinary-cni.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/node-unordinary-cni.png\" alt=\"Kubernetes Node Unordinary CNI\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>As an example, there might <em>not</em> be a <code>docker0</code> bridge; the AWS CNI is an\nexample of such CNI. In order to understand the reason of this choice, let’s\ninvestigate on how EC2 networking works.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni.png\" alt=\"Kubernetes AWS CNI Multiple ENI\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>In AWS, each EC2 instance can have multiple network interfaces (ENIs) and each\nof them can be assigned a limited number of IPs. For example, an <code>m5.large</code> can\nhave up to 10 IPs for ENI; out of those 10 IPs one of them has to be assigned to\nthe network interface itself while the remaining can be assigned freely.</p>\n<p>In the past, these extra IPs were assign to Pods but there was a big limit: the\nnumber of assignable IP addresses for each node.</p>\n<p>Let’s have a look at an example.</p>\n<p>An <code>m5.large</code> EC2 instance can have up to 3 ENIs with 10 IP private addresses\neach. Since one IP is reserved for the ENI, remains left 9 addresses per ENI and\nthus 27 in total. As a conseuences the EC2 <code>m5.large</code> could run up to 27 Pods,\nnot a lot actually.</p>\n<h2>Let’s enter prefixes</h2>\n<p>In August 2021 AWS <a href=\"https://aws.amazon.com/it/about-aws/whats-new/2021/07/amazon-virtual-private-cloud-vpc-customers-can-assign-ip-prefixes-ec2-instances/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">released a change</a>\nto EC2 that allows <em>prefixes</em> to be assigned to network interfaces.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni-prefix.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni-prefix.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/aws-cni-multiple-eni-prefix.png\" alt=\"Kubernetes AWS CNI Multiple ENI using prefixes\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>Prefixes?! In simple words, instead of supporting a single IP address, ENIs now\nsupport an IP range. Thus the same EC2 instance, which had 10 private IP\naddresses, now can have 10 <strong>ranges</strong> of IP addresses. And how big is the range?\nBy default, 16 IP addresses; so with 10 ranges <span class=\"wrapper svelte-1sgfl7c\">you could have\nup to 160 IP addresses</span>.</p>\n<p>Let’s have a look at another example.</p>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-pods-prefix.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/aws-eks-high-density-pods/aws-cni-pods-prefix.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/aws-eks-high-density-pods/aws-cni-pods-prefix.png\" alt=\"Kubernetes AWS CNI pods prefixes\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>An <code>m5.large</code> can have 3 ENIs with 10 slots each for IPs or <em>prefixes</em>; since\none IP is reserved for the ENI, you’re left with 9 <em>prefixes</em>. Each prefix is 16\nIPs, so <code>9*16=144</code> IPs. Since there are 3 ENIs, <code>144x3=432</code> IPs.</p>\n<p>The same EC2 can now runs <span class=\"wrapper svelte-1sgfl7c\">up to 432 Pods</span>, not\nonly 27 as before!</p>\n<h2>AWS CNI 1.9 and Pod-per-node limit</h2>\n<p>The <a href=\"https://aws.amazon.com/it/blogs/containers/amazon-vpc-cni-increases-pods-per-node-limits/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">AWS CNI 1.9.0</a> includes support to prefixes and\ncaps the max number of Pods to 110 or 250 so you won’t be able to run 432 Pods\non an m5.large; the latter in comòiance with the official <a href=\"https://kubernetes.io/docs/setup/best-practices/cluster-large/\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Kubernetes large clusters</a>\nguide recommendation. The CNI is also tunable and will prewarm IPs and prefixes\nso that your Pods start instantly.</p>\n<p>So… in order to answer the question at the beginning of this post, her’s why\nthe AWS-CNI 1.9.0 release (hopefully) makes more sense now!</p>","css":{"code":"picture.svelte-1gy5t1o.svelte-1gy5t1o{position:relative;width:100%;height:100%}picture.svelte-1gy5t1o img.svelte-1gy5t1o{width:100%;height:100%}\n.wrapper.svelte-1sgfl7c{background:var(--highlight-marker-url)}","map":null},"head":"","readingTime":"4 min read","relatedPosts":[{"slug":"vmworld-2021-as-speaker","title":"VMworld 2021 as speaker","date":"2021-10-11T00:00:00.000Z","excerpt":"VMworld 2021 has just ended... the first VMworld I took part in... as speaker!","tags":["Events","Cloud","Communities","VMware"],"html":"<p>VMworld 2021 has just ended! Due to the health worldwide emergency, the event\ntook place virtually. There were three days, from October 5th to 7th, full of\nkeynotes, sessions, round-tables and other social moments like were available\nonline and watchable directly from the people sofa!</p>\n<p>Among the other events, my good friend <a href=\"https://blog.linoproject.net\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">Lino Telera</a>\nand me took a speech about Tanzu and how it can be used on different automation\nscenarios, both on infrastructure and application side.</p>\n<h2>My first time VMworld… as speaker</h2>\n<p>Even though it was not the first world tech conference I took part at, it has\nbeen the first time at a VMworld! For sure the priceless experience on\nconference is the possibility of networking (that’s also the most difficult part\nto replicate in a remote experience), the conference surprised me with the\ncompleteness of content for all the technical fields.</p>\n<p>Moreover being speaker at a world-wide event, gave me the right excitement\nnecessary to enjoy the conference at best and pushed me to perform better on the\n“virtual stage”! I don’t want to hide my head under the sand: the tension was\nvery high and I felt like the so-called <em>demo effect</em> was hunting for me…</p>\n<p>In the end all want for the best; In the next few lines I want to give you a\ngeneral overview of the speech.</p>\n<h2>Automate DevOps in a Cloud Native Way with VMware Tanzu</h2>\n<figure><picture class=\"svelte-1gy5t1o\"><source srcset=\"/images/posts/vmworld-2021-as-speaker/presenting.avif\" type=\"image/avif\">\n    <source srcset=\"/images/posts/vmworld-2021-as-speaker/presenting.webp\" type=\"image/webp\">\n    <img src=\"/images/posts/vmworld-2021-as-speaker/presenting.png\" alt=\"Screenshot of my Slides\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1gy5t1o\"></picture>\n  \n</figure>\n<p>The recording of the speech is available on the <a href=\"https://www.vmware.com/vmworld/en/video-library/video-landing.html?sessionid=1620811753703001Iuro\" rel=\"nofollow noopener noreferrer\" target=\"_blank\">VMworld On-Demand Video Library</a>.</p>\n<p>As a <em>Cloud Native Platform Engineer</em>, automation takes a big part of my\neveryday work, therefore I’ve spent a lot of time researching, designing,\ndeveloping and maintaining systems aimed at automating the work of both\ninfrastructure engineers and software developers.</p>\n<p>During the last years, I had the great opportunity to work with Lino Telera and\nbring all my experience on the field to realize a hybrid cloud infrastructure\nintegration and <span class=\"wrapper svelte-1sgfl7c\">pipelines for continuous integrations &amp;\ndelivery</span>; with the aim to automate the deployment of the\ninfrastructures and the whole applications lifecycle.</p>\n<p>In our session we have shown how VMware Tanzu and Tanzu Kubernetes Grid can take\nan important role in the automation field and how they can be integrated with a\nlot of DevOps technologies like Jenkins, Gitlab, Tekton, Flux, and Terraform.</p>\n<p>The presentation was oriented not only to infrastructure automation people but\nalso to DevOps pipeline because contained also application development scenarios\nand real-case demos.</p>\n<h2>What’s next?</h2>\n<p>That was not all! Another great experience happened during the VMworld days; it\nhas been such a great experience that it’s worth a dedicated blog post… so\nstay tuned!</p>","css":{"code":"picture.svelte-1gy5t1o.svelte-1gy5t1o{position:relative;width:100%;height:100%}picture.svelte-1gy5t1o img.svelte-1gy5t1o{width:100%;height:100%}\n.wrapper.svelte-1sgfl7c{background:var(--highlight-marker-url)}","map":null},"head":"","readingTime":"3 min read"}]}